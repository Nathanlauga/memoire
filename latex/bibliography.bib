@misc{turing_browse_1951,
	address = {BBC},
	title = {Browse the {Turing} {Digital} {Archive}},
	url = {http://www.turingarchive.org/browse.php/B/5},
	language = {English},
	urldate = {2020-04-20},
	journal = {Can digital computers think ?},
	author = {Turing, Alan},
	month = may,
	year = {1951},
	file = {Browse the Turing Digital Archive:/home/lauga/Zotero/storage/XB8DELWB/5.html:text/html}
}

@misc{bush_as_1945,
	title = {As {We} {May} {Think}},
	url = {https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/},
	abstract = {“Consider a future device …  in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility. It is an enlarged intimate supplement to his memory.”},
	language = {en-US},
	urldate = {2019-07-18},
	journal = {The Atlantic},
	author = {Bush, Vannevar},
	month = jul,
	year = {1945},
	file = {Snapshot:/home/lauga/Zotero/storage/W5M3FTYT/303881.html:text/html}
}

@misc{krauthammer_be_1997,
	title = {Be {Afraid}},
	url = {https://www.weeklystandard.com/charles-krauthammer/be-afraid-9802},
	abstract = {"What we have is the world's best chess player vs. Garry Kasparov."},
	language = {en},
	urldate = {2019-07-18},
	journal = {The Weekly Standard},
	author = {Krauthammer, Charles},
	month = may,
	year = {1997},
	file = {Snapshot:/home/lauga/Zotero/storage/Y32XF8GZ/be-afraid-9802.html:text/html}
}

@inproceedings{hsu_deep_1995,
	address = {New York, NY, USA},
	series = {{ICS} '95},
	title = {Deep {Blue} {System} {Overview}},
	isbn = {978-0-89791-728-5},
	url = {http://doi.acm.org/10.1145/224538.224567},
	doi = {10.1145/224538.224567},
	urldate = {2019-07-18},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Supercomputing}},
	publisher = {ACM},
	author = {Hsu, Feng-hsiung and Campbell, Murray S. and Hoane, Jr., A. Joseph},
	year = {1995},
	note = {event-place: Barcelona, Spain},
	pages = {240--244},
	file = {Version soumise:/home/lauga/Zotero/storage/TVPAR9KQ/Hsu et al. - 1995 - Deep Blue System Overview.pdf:application/pdf}
}

@misc{deepmind_alphago_2016,
	title = {{AlphaGo}},
	url = {https://deepmind.com/research/alphago/},
	urldate = {2019-07-18},
	journal = {DeepMind},
	author = {{DeepMind}},
	year = {2016},
	file = {Snapshot:/home/lauga/Zotero/storage/MT3VBW9D/alphago.html:text/html}
}

@inproceedings{medeot_structurenet:_2018,
	title = {{StructureNet}: {Inducing} {Structure} in {Generated} {Melodies}},
	booktitle = {{ISMIR}},
	author = {Medeot, Gabriele and Cherla, Srikanth and Kosta, Katerina and McVicar, Matt and Abdallah, Samer and Selvi, Marco and Newton-Rex, Ed and Webster, Kevin},
	year = {2018}
}

@article{karras_style-based_2018,
	title = {A {Style}-{Based} {Generator} {Architecture} for {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1812.04948},
	abstract = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-speciﬁc control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
	language = {en},
	urldate = {2019-07-18},
	journal = {arXiv:1812.04948 [cs, stat]},
	author = {Karras, Tero and Laine, Samuli and Aila, Timo},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.04948},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: CVPR 2019 final version},
	file = {Karras et al. - 2018 - A Style-Based Generator Architecture for Generativ.pdf:/home/lauga/Zotero/storage/GZMYT3B2/Karras et al. - 2018 - A Style-Based Generator Architecture for Generativ.pdf:application/pdf}
}

@article{grace_when_2017,
	title = {When {Will} {AI} {Exceed} {Human} {Performance}? {Evidence} from {AI} {Experts}},
	shorttitle = {When {Will} {AI} {Exceed} {Human} {Performance}?},
	url = {http://arxiv.org/abs/1705.08807},
	abstract = {Advances in artiﬁcial intelligence (AI) will transform modern life by reshaping transportation, health, science, ﬁnance, and the military [1, 2, 3]. To adapt public policy, we need to better anticipate these advances [4, 5]. Here we report the results from a large survey of machine learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years,bush_as_1945 such as translating languages (by 2024), writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a bestselling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50\% chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years, with Asian respondents expecting these dates much sooner than North Americans. These results will inform discussion amongst researchers and policymakers about anticipating and managing trends in AI.},
	language = {en},
	urldate = {2019-07-18},
	journal = {arXiv:1705.08807 [cs]},
	author = {Grace, Katja and Salvatier, John and Dafoe, Allan and Zhang, Baobao and Evans, Owain},
	month = may,
	year = {2017},
	note = {arXiv: 1705.08807},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	annote = {Comment: Accepted by Journal of Artificial Intelligence Research (AI and Society Track). Minor update to refer to related work (page 5)},
	file = {Grace et al. - 2017 - When Will AI Exceed Human Performance Evidence fr.pdf:/home/lauga/Zotero/storage/3MMNEUWF/Grace et al. - 2017 - When Will AI Exceed Human Performance Evidence fr.pdf:application/pdf}
}

@book{harari_sapiens:_2015,
	address = {Paris},
	title = {Sapiens: une brève histoire de l'humanité},
	isbn = {978-2-226-25701-7},
	shorttitle = {Sapiens},
	abstract = {Il y a 100 000 ans, la Terre était habitée par au moins six espèces différentes d'hominidés. Une seule a survécu. Nous, les Homo Sapiens. Comment notre espèce a-t-elle réussi à dominer la planète ? Pourquoi nos ancêtres ont-ils uni leurs forces pour créer villes et royaumes ? Comment en sommes-nous arrivés à créer les concepts de religion, de nation, de droits de l'homme ? A dépendre de l'argent, des livres et des lois ? A devenir esclaves de la bureaucratie, des horaires, de la consommation de masse ? Et à quoi ressemblera notre monde dans le millénaire à venir ? Véritable phénomène d'édition, traduit dans une trentaine de langues, Sapiens est un livre audacieux, érudit et provocateur. Professeur d'Histoire à l'Université hébraïque de Jérusalem, Yuval Noah Harari mêle l'Histoire à la Science pour remettre en cause tout ce que nous pensions savoir sur l'humanité : nos pensées, nos actes, notre héritage... et notre futur. (Payot.ch)},
	language = {French},
	publisher = {Albin Michel},
	author = {Harari, Yuval N and Dauzat, Pierre-Emmanuel},
	year = {2015},
	note = {OCLC: 1082432348}
}

@incollection{ducat_du_2017,
	address = {Paris},
	series = {Mètis},
	title = {Du vol dans l’éducation spartiate},
	isbn = {978-2-7132-2599-4},
	url = {http://books.openedition.org/editionsehess/2103},
	abstract = {Reprenant le problème du vol dans l’éducation spartiate, cette étude réexamine d’abord les sources textuelles du dossier. Après avoir, en un second temps, fait appel à des parallèles ethnographiques, l’enquête revient à la société spartiate pour examiner comment le vol s’intègre aux autres pratiques éducatives : le rite à l’autel d’Orthia, la cryptie, l’encadrement et la surveillance des jeunes par les adultes. Le paradoxe d’une conduite à la fois imposée et punie obéit à la logique de l’épreuve et à celle de l’inversion, toutes deux typiques des pratiques initiatiques. La comparaison ethnologique avec des sociétés « archaïques » contemporaines n’explique certainement pas la pratique spartiate. Elle permet toutefois d’entrevoir comment à Sparte le modèle initiatique a été remodelé et repensé pour être intégré à la vie sociale et à la formation du futur citoyen.},
	urldate = {2019-07-18},
	booktitle = {Dossier : {Alexandre} le {Grand}, religion et tradition},
	publisher = {Éditions de l’École des hautes études en sciences sociales},
	author = {Ducat, Jean},
	month = jun,
	year = {2017},
	keywords = {Alexander The Great, Alexandre le Grand, historiographie, religion},
	pages = {95--110}
}

@book{kant_fondements_2007,
	address = {Paris},
	title = {Fondements de la métaphysique des mœurs},
	isbn = {978-2-206-00155-5},
	language = {French},
	publisher = {Libraire Delagrave},
	author = {Kant, Immanuel and Delbos, Victor},
	year = {2007},
	note = {OCLC: 612252890}
}

@article{kohlberg_moral_1977,
	title = {Moral development: {A} review of the theory},
	volume = {16},
	issn = {0040-5841, 1543-0421},
	shorttitle = {Moral development},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00405847709542675},
	doi = {10.1080/00405847709542675},
	language = {en},
	number = {2},
	urldate = {2019-07-18},
	journal = {Theory Into Practice},
	author = {Kohlberg, Lawrence and Hersh, Richard H.},
	month = apr,
	year = {1977},
	pages = {53--59}
}

@misc{alexandre_laurent_2017,
	title = {Laurent {Alexandre} : {Intelligence} artificielle [{EN} {DIRECT}] - {YouTube}},
	url = {https://www.youtube.com/watch?v=QS951xiGGvI},
	urldate = {2019-07-18},
	author = {Alexandre, Laurent},
	month = nov,
	year = {2017},
	file = {Laurent Alexandre \: Intelligence artificielle [EN DIRECT] - YouTube:/home/lauga/Zotero/storage/KRXJBRDZ/watch.html:text/html}
}

@article{greenwald_implicit_1995,
	title = {Implicit social cognition: attitudes, self-esteem, and stereotypes},
	volume = {102},
	issn = {0033-295X},
	shorttitle = {Implicit social cognition},
	abstract = {Social behavior is ordinarily treated as being under conscious (if not always thoughtful) control. However, considerable evidence now supports the view that social behavior often operates in an implicit or unconscious fashion. The identifying feature of implicit cognition is that past experience influences judgment in a fashion not introspectively known by the actor. The present conclusion--that attitudes, self-esteem, and stereotypes have important implicit modes of operation--extends both the construct validity and predictive usefulness of these major theoretical constructs of social psychology. Methodologically, this review calls for increased use of indirect measures--which are imperative in studies of implicit cognition. The theorized ordinariness of implicit stereotyping is consistent with recent findings of discrimination by people who explicitly disavow prejudice. The finding that implicit cognitive effects are often reduced by focusing judges' attention on their judgment task provides a basis for evaluating applications (such as affirmative action) aimed at reducing such unintended discrimination.},
	language = {eng},
	number = {1},
	journal = {Psychological Review},
	author = {Greenwald, A. G. and Banaji, M. R.},
	month = jan,
	year = {1995},
	pmid = {7878162},
	keywords = {Attitude, Humans, Prejudice, Self Concept, Social Behavior, Social Perception, Stereotyping, Unconscious (Psychology)},
	pages = {4--27}
}

@misc{larson_how_2016,
	type = {text/html},
	title = {How {We} {Analyzed} the {COMPAS} {Recidivism} {Algorithm}},
	copyright = {Copyright ©2019 ProPublica.},
	url = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
	abstract = {ProPublica is an independent, non-profit newsroom that produces investigative journalism in the public interest.},
	language = {en},
	urldate = {2019-07-18},
	journal = {ProPublica},
	author = {Larson, Jeff and Angwin, Julia},
	month = may,
	year = {2016},
	file = {Snapshot:/home/lauga/Zotero/storage/FPI7UH58/how-we-analyzed-the-compas-recidivism-algorithm.html:text/html}
}

@misc{clement_global_2019,
	title = {Global social media ranking 2019},
	url = {https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/},
	abstract = {How many people use social media? This statistic shows the most famous social networks worldwide as of April 2019. Market leader Facebook currently sits at 2.32 billion monthly active users.},
	language = {en},
	urldate = {2019-07-18},
	journal = {Statista},
	author = {Clement, J.},
	year = {2019},
	file = {Snapshot:/home/lauga/Zotero/storage/KVJUPHPM/global-social-networks-ranked-by-number-of-users.html:text/html}
}

@article{kramer_correction_2014,
	title = {Correction for {Kramer} et al., {Experimental} evidence of massive-scale emotional contagion through social networks},
	volume = {111},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1412583111},
	doi = {10.1073/pnas.1412583111},
	language = {en},
	number = {29},
	urldate = {2019-07-18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kramer, Adam and Guillory, Jamie and Hancock, Jeffrey},
	month = jul,
	year = {2014},
	pages = {10779--10779},
	file = {Texte intégral:/home/lauga/Zotero/storage/8KWLYHBV/2014 - Correction for Kramer et al., Experimental evidenc.pdf:application/pdf}
}

@misc{desjardins_infographic:_2018,
	title = {Infographic: {What} {Happens} in an {Internet} {Minute} in 2018?},
	url = {https://www.visualcapitalist.com/internet-minute-2018/},
	urldate = {2019-07-18},
	journal = {Visual Capitalist},
	author = {Desjardins, Jeff},
	month = may,
	year = {2018},
	file = {Infographic\: What Happens in an Internet Minute in 2018?:/home/lauga/Zotero/storage/UIT3SJWJ/internet-minute-2018.html:text/html}
}

@phdthesis{launay_urnes_2012,
	type = {thesis},
	title = {Urnes interagissantes},
	url = {http://www.theses.fr/2012AIXM4775},
	abstract = {Nous nous intéressons au comportement asymptotique de plusieurs urnes de type Polya fortement renforcées et interagissantes. Le principal de notre étude porte sur les renforcements exponentiels ou assimilés ainsi que sur les interactions temporelles, c'est-à-dire lors desquelles les urnes n'interagissent qu'à certains instants aléatoires. Dans ce cas, nous mettons en évidence une transition de phase selon la fréquence des interactions. Si celle ci est supérieure à 1/2, les urnes se fixent toutes sur la même couleur tandis que si elle est inférieure à 1/2, une couleur majoritaire se dégage mais certaines urnes peuvent continuer à tirer une autre couleur aux instants où il n'y a pas interaction. Lorsque le renforcement devient infini, nous pouvons calculer la loi du nombre d'urnes se comportant de cette dernière façon quand le nombre total d'urnes est égal à deux ou est un nombre impair.Quand l'interaction est totale, c'est-à-dire quand toutes les urnes interagissent à tout instant, nous montrons alors qu'un renforcement fort et croissant, mais plus nécessairement exponentiel, suffit à obtenir la fixation de toutes les urnes sur la même couleur.Pour finir, nous discutons brièvement du modèle d'interaction spatiale dans lequel les urnes sont situées sur les sommets d'un graphe et n'interagissent qu'avec leurs voisines. Nous dégageons alors quelques propriétés préliminaires concernant les sous-graphes susceptibles de se fixer sur une couleur avec une probabilité positive.},
	urldate = {2019-07-18},
	school = {Aix-Marseille},
	author = {Launay, Mickaël},
	month = jun,
	year = {2012},
	keywords = {Graphes, Théorie des -- Thèses et écrits académiques, Interactions, Mathématiques, Polya, Pólya, George (1887-1985), Probabilités, Probabilités -- Thèses et écrits académiques, Probability, Processus renforcés, Reinforced processes, Urnes, Urns},
	file = {Full Text PDF:/home/lauga/Zotero/storage/NKECLGIZ/Launay - 2012 - Urnes interagissantes.pdf:application/pdf;Snapshot:/home/lauga/Zotero/storage/CG2L6VH4/2012AIXM4775.html:text/html}
}

@article{gilpin_explaining_2018,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	url = {http://arxiv.org/abs/1806.00069},
	abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we provide our definition of explainability and show how it can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
	urldate = {2019-07-18},
	journal = {arXiv:1806.00069 [cs, stat]},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = may,
	year = {2018},
	note = {arXiv: 1806.00069},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: The 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA 2018). [Research Track]},
	file = {arXiv\:1806.00069 PDF:/home/lauga/Zotero/storage/HBZM2UTR/Gilpin et al. - 2018 - Explaining Explanations An Overview of Interpreta.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/2KI6IMX9/1806.html:text/html}
}

@misc{data_for_good_serment_2018,
	title = {Serment d'{Hippocrate} pour data scientist},
	url = {https://www.hippocrate.tech},
	abstract = {En tant que professionnel(le) amené(e) à
collecter, stocker, traiter, modéliser, analyser des données et/ou à concevoir des algorithmes, des produits informatiques ou des interfaces,
je suis conscient(e) de l’impact
que peut avoir mon travail sur des individus et sur la société dans son ensemble.},
	urldate = {2019-07-18},
	author = {{Data for Good}},
	year = {2018},
	file = {Snapshot:/home/lauga/Zotero/storage/BRCSUQF9/hippocrate.tech.html:text/html}
}

@article{awad_moral_2018,
	title = {The {Moral} {Machine} experiment},
	volume = {563},
	copyright = {2018 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0637-6},
	doi = {10.1038/s41586-018-0637-6},
	abstract = {Responses from more than two million people to an internet-based survey of attitudes towards moral dilemmas that might be faced by autonomous vehicles shed light on similarities and variations in ethical preferences among different populations.},
	language = {En},
	number = {7729},
	urldate = {2019-07-18},
	journal = {Nature},
	author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
	month = nov,
	year = {2018},
	pages = {59},
	file = {Snapshot:/home/lauga/Zotero/storage/UIGJ8WYX/s41586-018-0637-6.html:text/html}
}

@article{hoang_roadmap_2018,
	title = {A {Roadmap} for {Robust} {End}-to-{End} {Alignment}},
	url = {http://arxiv.org/abs/1809.01036},
	abstract = {We analyze the AI alignment problem. This is the problem of aligning an AI's objective function with human preferences. This problem has been argued to be critical to AI safety, especially in the long run. But it has also been argued that solving it robustly is extremely challenging, especially in highly complex environments like the Internet. It seems crucial to accelerate research in this direction. To this end, we propose a preliminary research program. Our roadmap aims to decompose alignment into numerous more tractable subproblems. Our hope is that this will help scholars, engineers and decision-makers to better grasp the upcoming difficulties, and to foresee how they can best contribute to the global effort.},
	urldate = {2019-07-18},
	journal = {arXiv:1809.01036 [cs]},
	author = {Hoang, Lê Nguyên},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.01036},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 25 pages, 4 figures},
	file = {arXiv\:1809.01036 PDF:/home/lauga/Zotero/storage/DEEQE8I4/Hoang - 2018 - A Roadmap for Robust End-to-End Alignment.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/3BIMFGR4/1809.html:text/html}
}

@article{irving_ai_2019,
	title = {{AI} {Safety} {Needs} {Social} {Scientists}},
	volume = {4},
	issn = {2476-0757},
	url = {https://distill.pub/2019/safety-needs-social-scientists},
	doi = {10.23915/distill.00014},
	number = {2},
	urldate = {2019-07-18},
	journal = {Distill},
	author = {Irving, Geoffrey and Askell, Amanda},
	month = feb,
	year = {2019},
	pages = {10.23915/distill.00014}
}

@article{grudin_ai_2009,
	title = {{AI} and {HCI}: {Two} {Fields} {Divided} by a {Common} {Focus}},
	volume = {30},
	issn = {0738-4602, 0738-4602},
	shorttitle = {{AI} and {HCI}},
	url = {https://aaai.org/ojs/index.php/aimagazine/article/view/2271},
	doi = {10.1609/aimag.v30i4.2271},
	abstract = {Although AI and HCI explore computing and intelligent behavior and the fields have seen some cross-over, until recently there was not very much. This article outlines a history of the fields that identifies some of the forces that kept the fields at arm’s length. AI was generally marked by a very ambitious, long-term vision requiring expensive systems, although the term was rarely envisioned as being as long as it proved to be, whereas HCI focused more on innovation and improvement of widely-used hardware within a short time-scale. These differences led to different priorities, methods, and assessment approaches.  A consequence was competition for resources, with HCI flourishing in AI winters and moving more slowly when AI was in favor. The situation today is much more promising, in part because of platform convergence: AI can be exploited on widely-used systems.},
	language = {en},
	number = {4},
	urldate = {2019-07-18},
	journal = {AI Magazine},
	author = {Grudin, Jonathan},
	month = sep,
	year = {2009},
	pages = {48},
	file = {Grudin - 2009 - AI and HCI Two Fields Divided by a Common Focus.pdf:/home/lauga/Zotero/storage/PV4EVZ2Q/Grudin - 2009 - AI and HCI Two Fields Divided by a Common Focus.pdf:application/pdf}
}

@article{appleton_ignoring_1996,
	title = {Ignoring a {Covariate}: {An} {Example} of {Simpson}'s {Paradox}},
	volume = {50},
	issn = {0003-1305},
	shorttitle = {Ignoring a {Covariate}},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1996.10473563},
	doi = {10.1080/00031305.1996.10473563},
	abstract = {The possibility that the apparent direction of an association will be reversed when covariates are taken into account is well known, but many examples of this effect are rather contrived. A real example from an epidemiological survey is presented.},
	number = {4},
	urldate = {2019-07-18},
	journal = {The American Statistician},
	author = {Appleton, David R. and French, Joyce M. and Vanderpump, Mark P. J.},
	month = nov,
	year = {1996},
	pages = {340--341},
	file = {Snapshot:/home/lauga/Zotero/storage/FCS7HWTD/00031305.1996.html:text/html}
}

@article{bellamy_ai_2018,
	title = {{AI} {Fairness} 360: {An} {Extensible} {Toolkit} for {Detecting}, {Understanding}, and {Mitigating} {Unwanted} {Algorithmic} {Bias}},
	shorttitle = {{AI} {Fairness} 360},
	url = {http://arxiv.org/abs/1810.01943},
	abstract = {Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license \{\vphantom{\}}https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.},
	urldate = {2019-07-18},
	journal = {arXiv:1810.01943 [cs]},
	author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.01943},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 20 pages},
	file = {arXiv\:1810.01943 PDF:/home/lauga/Zotero/storage/5XUXNW5M/Bellamy et al. - 2018 - AI Fairness 360 An Extensible Toolkit for Detecti.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/Q85BEY6H/1810.html:text/html}
}

@incollection{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
	urldate = {2019-07-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {4765--4774},
	file = {NIPS Full Text PDF:/home/lauga/Zotero/storage/QZTV77ZG/Lundberg et Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf;NIPS Snapshot:/home/lauga/Zotero/storage/E8IFV5ZK/7062-a-unified-approach-to-interpreting-model-predictions.html:text/html}
}

@misc{manea_strategy_2016,
	title = {Strategy and {Information}},
	url = {https://ocw.mit.edu/courses/economics/14-16-strategy-and-information-spring-2016/},
	abstract = {This is an advanced course in game theory. We begin with a rigorous overview of the main\&nbsp;equilibrium concepts for non-\&shy;cooperative games in both static and dynamic settings with either complete or incomplete information. We define and explore properties of iterated strict dominance, rationalizability, Nash equilibrium, subgame perfection, sequential, perfect and proper equilibria, the intuitive criterion, and iterated weak dominance. We discuss applications to auctions, bargaining, and repeated games. Then we introduce solution concepts for cooperative games and study non-\&shy;cooperative  implementations.\&nbsp;Other topics include matching theory and networks.\&nbsp;},
	language = {en},
	urldate = {2019-07-18},
	journal = {MIT OpenCourseWare},
	author = {Manea, Mihai},
	year = {2016},
	file = {Snapshot:/home/lauga/Zotero/storage/9EGXLMQN/index.html:text/html}
}

@phdthesis{cointe_ethical_2017,
	type = {Theses},
	title = {Ethical {Judgment} for decision and cooperation in multiagent systems},
	url = {https://tel.archives-ouvertes.fr/tel-01851485},
	school = {Université de Lyon},
	author = {Cointe, Nicolas},
	month = dec,
	year = {2017},
	keywords = {Computational ethics, Cooperation, Éthique computationnelle, Judgment, Jugement, Multiagent systems, Systèmes multi-agents}
}

@book{crevier_ai:_1992,
	address = {New York, NY},
	title = {{AI}: the tumultuous history of the search for artificial intelligence},
	isbn = {978-0-465-02997-6 978-0-465-00104-0},
	shorttitle = {{AI}},
	abstract = {"In the summer of 1956, ten young scientists, some barely out of their doctoral studies, sat down to consider the astounding proposition that "every aspect of learning or any other feature of intelligence can, in principle, be so precisely described that a machine can be made to simulate it." Armed with their own enthusiasm, the excitement of the idea itself, and an infusion of government money, they predicted that the whole range of human intelligence would be programmable within their own lifetimes. Nearly half a century later, the field has grown exponentially - with mixed results." "Based on extensive interviews with the major players, including Marvin Minsky, Herbert Simon, Allen Newell, Raj Reddy, and Patrick Winston, AI is part intellectual history, part business history. Rich with anecdotes about the founders and leaders of the field and their celebrated feuds and intellectual gamesmanship, the book chronicles their dramatic successes ("expert" systems, robotics, "smart" technologies, and even world-class chess playing) and their equally dramatic failures (language processing, learning), and shows how early in the next century researchers hope to teach their computers "common sense," the next necessary breakthrough." "The story of AI is an exhilarating saga of new programs and new hardware, yet it is also the story of a slow but steady acquisition of knowledge about how humans think. Daniel Crevier traces AI's emergence from the fields of philosophy, mathematics, psychology, and neurology, chronicling the development of primitive computing devices and ultimately the creation of a brave new world described chiefly in acronyms: SOAR, Cyc, EURISKO, among others." "The quest for artificial intelligence raises profound issues about the nature of mind and soul as well as fascinating philosophical questions. Will we humans one day have to share our world with entities smarter than ourselves? And can we rely on these creations to make vital decisions for us - business, scientific, legal, and even moral choices? Crevier discusses these questions with the leaders of AI, and they offer some surprising answers."--Jacket.},
	language = {English},
	publisher = {Basic Books},
	author = {Crevier, Daniel},
	year = {1992},
	note = {OCLC: 26858345}
}

@article{floridi_unified_2019,
	title = {A {Unified} {Framework} of {Five} {Principles} for {AI} in {Society}},
	url = {https://hdsr.mitpress.mit.edu/pub/l0jsh9d1},
	doi = {10.1162/99608f92.8cd550d1},
	language = {en},
	urldate = {2019-10-24},
	author = {Floridi, Luciano and Cowls, Josh},
	month = jun,
	year = {2019},
	file = {Snapshot:/home/lauga/Zotero/storage/A6Q56BP4/l0jsh9d1.html:text/html}
}

@article{jobin_artificial_2019,
	title = {Artificial {Intelligence}: the global landscape of ethics guidelines},
	volume = {1},
	issn = {2522-5839},
	shorttitle = {Artificial {Intelligence}},
	url = {http://arxiv.org/abs/1906.11668},
	doi = {10.1038/s42256-019-0088-2},
	abstract = {In the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical AI, yet there is debate about both what constitutes "ethical AI" and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.},
	number = {9},
	urldate = {2019-10-24},
	journal = {Nature Machine Intelligence},
	author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
	month = sep,
	year = {2019},
	note = {arXiv: 1906.11668},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	pages = {389--399},
	annote = {Comment: 42 pages (incl. figures and supplementary information)},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/LIEU47XY/Jobin et al. - 2019 - Artificial Intelligence the global landscape of e.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/G2WEWU3A/1906.html:text/html}
}

@misc{jordan_organizing_2018,
	title = {Organizing machine learning projects: project management guidelines.},
	shorttitle = {Organizing machine learning projects},
	url = {https://www.jeremyjordan.me/ml-projects-guide/},
	abstract = {The goal of this document is to provide a common framework for approaching machine learning projects that can be referenced by practitioners. If you build ML models, this post is for you. If you collaborate with people who build ML models, I hope that this guide provides you with a},
	urldate = {2019-10-24},
	journal = {Jeremy Jordan},
	author = {Jordan, Jeremy},
	month = sep,
	year = {2018},
	file = {Snapshot:/home/lauga/Zotero/storage/3YD8MJCN/ml-projects-guide.html:text/html}
}

@misc{mayo_machine_2018,
	title = {The {Machine} {Learning} {Project} {Checklist}},
	url = {https://www.kdnuggets.com/the-machine-learning-project-checklist.html/},
	abstract = {In an effort to further refine our internal models, this post will present an overview of Aurélien Géron's Machine Learning Project Checklist, as seen in his bestselling book, "Hands-On Machine Learning with Scikit-Learn \& TensorFlow."},
	language = {en-US},
	urldate = {2019-10-24},
	journal = {KDnuggets},
	author = {Mayo, Matthew},
	month = dec,
	year = {2018},
	file = {Snapshot:/home/lauga/Zotero/storage/PBM3BGE4/machine-learning-project-checklist.html:text/html}
}

@article{hagendorff_ethics_2019,
	title = {The {Ethics} of {AI} {Ethics} -- {An} {Evaluation} of {Guidelines}},
	url = {http://arxiv.org/abs/1903.03425},
	abstract = {Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the "disruptive" potentials of new AI technologies. Designed as a comprehensive evaluation, this paper analyzes and compares these guidelines highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems - and how the effectiveness in the demands of AI ethics can be improved.},
	urldate = {2019-10-24},
	journal = {arXiv:1903.03425 [cs, stat]},
	author = {Hagendorff, Thilo},
	month = oct,
	year = {2019},
	note = {arXiv: 1903.03425},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society},
	annote = {Comment: 16 pages, 1 table},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/SWYZLX6A/Hagendorff - 2019 - The Ethics of AI Ethics -- An Evaluation of Guidel.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/7H65N9PK/1903.html:text/html}
}

@book{beauchamp_principles_2009,
	title = {Principles of {Biomedical} {Ethics}},
	isbn = {978-0-19-533570-5},
	abstract = {Building on the best-selling tradition of previous editions, Principles of Biomedical Ethics, Sixth Edition, provides a highly original, practical, and insightful guide to morality in the health professions. Acclaimed authors Tom L. Beauchamp and James F. Childress thoroughly develop and advocate for four principles that lie at the core of moral reasoning in health care: respect for autonomy, nonmaleficence, beneficence, and justice. Drawing from contemporary research--and integrating detailed case studies and vivid real-life examples and scenarios--they demonstrate how these prima facie principles can be expanded to apply to various conflicts and dilemmas, from how to deliver bad news to whether or not to withhold or withdraw life-sustaining treatments. Illuminating both theory and method throughout, Principles of Biomedical Ethics, Sixth Edition, considers what constitutes moral character and addresses the problem of moral status: what rights are due to people and animals, and when. It also examines the professional-patient relationship, surveys major philosophical theories--including utilitarianism, Kantianism, rights theory, and Communitarianism--and describes methods of moral justification in bioethics. Ideal for courses in biomedical ethics, bioethics, and health care ethics, the text is enhanced by hundreds of annotated citations and a substantial introduction that clarifies key terms and concepts.Features of the Sixth Edition: * Integrates case studies throughout the text, rather than presenting them in an appendix as in previous editions* A new chapter on moral status (Chapter 3)* Extensively revised and expanded material on the theory of the common morality (Chapters 1 and 10)* A reworked discussion of the ethics of care as a form of virtue ethics (Chapter 2)* Revised and updated treatments of nonmaleficence and beneficence, which take into account recent legal and philosophical literature and discussions (Chapters 5 and 6)* A new section on vulnerability and exploitation as it applies to justice (Chapter 7)* A more concise treatment of the principles of biomedical ethics throughout the text, featuring developed, refined, and modified perspectives},
	language = {en},
	publisher = {Oxford University Press},
	author = {Beauchamp, Tom L. and Childress, James F.},
	year = {2009},
	note = {Google-Books-ID: nreKPwAACAAJ},
	keywords = {Medical / Ethics, Philosophy / Ethics \& Moral Philosophy, Science / Life Sciences / Biology}
}

@misc{european_commission_ethics_2019,
	type = {Text},
	title = {Ethics guidelines for trustworthy {AI}},
	url = {https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai},
	abstract = {On 8 April 2019, the High-Level Expert Group on AI presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
	language = {en},
	urldate = {2019-11-01},
	journal = {Digital Single Market - European Commission},
	author = {European Commission},
	month = apr,
	year = {2019},
	file = {Snapshot:/home/lauga/Zotero/storage/QHKNPSVD/ethics-guidelines-trustworthy-ai.html:text/html}
}

@misc{dorad_machine_2016,
	title = {Machine {Learning} {Canvas}},
	url = {https://www.louisdorard.com/machine-learning-canvas},
	abstract = {Design better Machine Learning systems. Keep teams of scientists, engineers and managers focused on the same objectives.},
	language = {en-GB},
	urldate = {2019-11-02},
	journal = {Louis Dorard},
	author = {Dorad, Louis},
	year = {2016},
	file = {Snapshot:/home/lauga/Zotero/storage/UT66JXYK/machine-learning-canvas.html:text/html}
}

@article{dastin_amazon_2018,
	title = {Amazon scraps secret {AI} recruiting tool that showed bias against women},
	url = {https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G},
	abstract = {Amazon.com Inc's machine-learning specialists uncovered a big problem: thei...},
	language = {en},
	urldate = {2019-11-04},
	journal = {Reuters},
	author = {Dastin, Jeffrey and Weber, Jonathan and Dickerson, Marla},
	month = oct,
	year = {2018},
	keywords = {Company News, Europe, Pictures, Technology (TRBC), US, All Retail, AMAZON, AUTOMATION, COM, Department Stores (TRBC), Enterprise Reporting, General News, Government / Politics, Graphics, Human Rights / Civil Rights, Information Technologies / Computer Sciences, INSIGHT, Insights, Internet / World Wide Web, JOBS, Labour / Personnel, Major News, Science, Society / Social Issues, Software and IT Services (TRBC), Special Reports, Video, Women's Issues},
	file = {Snapshot:/home/lauga/Zotero/storage/CJ7CDUGF/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G.html:text/html}
}

@incollection{lundberg_unified_2017-1,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
	urldate = {2019-11-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {4765--4774},
	file = {NIPS Full Text PDF:/home/lauga/Zotero/storage/IAPIK8RH/Lundberg et Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf;NIPS Snapshot:/home/lauga/Zotero/storage/46S7UVHN/7062-a-unified-approach-to-interpreting-model-predictions.html:text/html}
}

@article{bellamy_ai_2018-1,
	title = {{AI} {Fairness} 360: {An} {Extensible} {Toolkit} for {Detecting}, {Understanding}, and {Mitigating} {Unwanted} {Algorithmic} {Bias}},
	shorttitle = {{AI} {Fairness} 360},
	url = {http://arxiv.org/abs/1810.01943},
	abstract = {Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license \{\vphantom{\}}https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.},
	urldate = {2019-11-04},
	journal = {arXiv:1810.01943 [cs]},
	author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.01943},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 20 pages},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/LDSV23VS/Bellamy et al. - 2018 - AI Fairness 360 An Extensible Toolkit for Detecti.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/PKX2IC4S/1810.html:text/html}
}

@book{poole_computational_1997,
	address = {New York, NY, USA},
	title = {Computational {Intelligence}: {A} {Logical} {Approach}},
	isbn = {0-19-510270-3},
	publisher = {Oxford University Press, Inc.},
	author = {Poole, David and Mackworth, Alan and Goebel, Randy},
	year = {1997}
}

@article{solomonoff_time_1985,
	title = {The time scale of artificial intelligence: {Reflections} on social effects},
	volume = {5},
	issn = {0167-2533},
	shorttitle = {The time scale of artificial intelligence},
	url = {https://content.iospress.com/articles/human-systems-management/hsm5-2-07},
	doi = {10.3233/HSM-1985-5207},
	abstract = {Six future milestones in AI are discussed. These range from the development of a very general theory of problem solving to the creation of machines with capacities well beyond those of a single human. Estimates are made for when these milestones will},
	language = {en},
	number = {2},
	urldate = {2019-07-18},
	journal = {Human Systems Management},
	author = {Solomonoff, R. J.},
	month = jan,
	year = {1985},
	pages = {149--153},
	file = {Full Text PDF:/home/lauga/Zotero/storage/NDSH2IIH/Solomonoff - 1985 - The time scale of artificial intelligence Reflect.pdf:application/pdf;Snapshot:/home/lauga/Zotero/storage/KBKJQH64/hsm5-2-07.html:text/html}
}

@article{turing_i.computing_1950,
	title = {I.—{COMPUTING} {MACHINERY} {AND} {INTELLIGENCE}},
	volume = {LIX},
	issn = {0026-4423},
	url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
	doi = {10.1093/mind/LIX.236.433},
	abstract = {A. M. TURING;  I.—COMPUTING MACHINERY AND INTELLIGENCE, Mind, Volume LIX, Issue 236, 1 October 1950, Pages 433–460, https://doi.org/10.1093/mind/LIX.236.433},
	language = {en},
	number = {236},
	urldate = {2019-07-18},
	journal = {Mind},
	author = {Turing, A. M.},
	month = oct,
	year = {1950},
	pages = {433--460},
	file = {Full Text PDF:/home/lauga/Zotero/storage/SPGGLABJ/Turing - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf:application/pdf;Snapshot:/home/lauga/Zotero/storage/737IBM7R/986238.html:text/html}
}

@book{wiener_cybernetique_2014,
	address = {Paris},
	title = {La cybernétique information et régulation dans le vivant et la machine},
	isbn = {978-2-02-109420-6},
	language = {French},
	publisher = {Editions du Seuil},
	author = {Wiener, Norbert and Le Roux, Ronan and Vallée, Robert and Vallée, Nicole},
	year = {2014},
	note = {OCLC: 879421361}
}

@article{pinar_saygin_turing_2000,
	title = {Turing {Test}: 50 {Years} {Later}},
	volume = {10},
	issn = {1572-8641},
	shorttitle = {Turing {Test}},
	url = {https://doi.org/10.1023/A:1011288000451},
	doi = {10.1023/A:1011288000451},
	abstract = {The Turing Test is one of the most disputed topics in artificial intelligence, philosophy of mind, and cognitive science. This paper is a review of the past 50 years of the Turing Test. Philosophical debates, practical developments and repercussions in related disciplines are all covered. We discuss Turing's ideas in detail and present the important comments that have been made on them. Within this context, behaviorism, consciousness, the `other minds' problem, and similar topics in philosophy of mind are discussed. We also cover the sociological and psychological aspects of the Turing Test. Finally, we look at the current situation and analyze programs that have been developed with the aim of passing the Turing Test. We conclude that the Turing Test has been, and will continue to be, an influential and controversial topic.},
	language = {en},
	number = {4},
	urldate = {2019-07-18},
	journal = {Minds and Machines},
	author = {Pinar Saygin, Ayse and Cicekli, Ilyas and Akman, Varol},
	month = nov,
	year = {2000},
	keywords = {chatbots, Chinese Room, consciousness, Imitation Game, intelligence, Loebner Contest, philosophy of mind, Turing Test},
	pages = {463--518},
	file = {Texte intégral:/home/lauga/Zotero/storage/9SHI6JE8/Pinar Saygin et al. - 2000 - Turing Test 50 Years Later.pdf:application/pdf}
}

@book{simon_shape_1965,
	address = {New York,},
	edition = {[1st ed.]},
	title = {The shape of automation for men and management,},
	publisher = {Harper \& Row},
	author = {Simon, Herbert A.},
	year = {1965},
	file = {The shape of automation for men and management in SearchWorks catalog:/home/lauga/Zotero/storage/V3A5EQMX/109399.html:text/html}
}

@article{simon_heuristic_1958,
	title = {Heuristic {Problem} {Solving}: {The} {Next} {Advance} in {Operations} {Research}},
	volume = {6},
	issn = {0030-364X},
	shorttitle = {Heuristic {Problem} {Solving}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/opre.6.1.1},
	doi = {10.1287/opre.6.1.1},
	abstract = {Address at the banquet of the Twelfth National Meeting of the Operations Research Society of America, Pittsburgh, Pennsylvania, November 14, 1957. Mr. Simon presented the paper; its content is a joint product of the authors. In this, they rely on the precedent of Genesis 27:22, “The voice is Jacob's voice, but the hands are the hands of Esau.”},
	number = {1},
	urldate = {2019-07-18},
	journal = {Operations Research},
	author = {Simon, Herbert A. and Newell, Allen},
	month = feb,
	year = {1958},
	pages = {1--10},
	file = {Snapshot:/home/lauga/Zotero/storage/JW4IJXKP/opre.6.1.html:text/html}
}

@misc{newsflash_ai_2018,
	title = {'{AI} is very, very stupid,' says {Google}'s {AI} leader, at least compared to humans - {CNET}},
	url = {https://newsflash.one/2018/11/14/ai-is-very-very-stupid-says-googles-ai-leader-at-least-compared-to-humans-cnet/},
	abstract = {Andrew Moore, VP of AI for Google Cloud, speaks at a Google AI event. Screenshot by Stephen Shankland/CNET The hype over artificial intelligence is getting pretty hot, so here’s a splash of cold water from none other than the leader of AI for Google’s cloud division. “AI is currently very, very stupid,” said Andrew Moore, …},
	language = {en-US},
	urldate = {2019-07-18},
	journal = {News Flash},
	author = {{newsflash}},
	month = nov,
	year = {2018},
	file = {Snapshot:/home/lauga/Zotero/storage/DXRKUVZ5/ai-is-very-very-stupid-says-googles-ai-leader-at-least-compared-to-humans-cnet.html:text/html}
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	copyright = {2017 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.},
	language = {en},
	number = {7676},
	urldate = {2019-07-18},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	pages = {354--359},
	file = {Snapshot:/home/lauga/Zotero/storage/CHEA4LDX/nature24270.html:text/html}
}

@book{vinyals_alphastar:_2019,
	title = {{AlphaStar}: {Mastering} the {Real}-{Time} {Strategy} {Game} {StarCraft} {II}},
	url = {https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/},
	author = {Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
	year = {2019}
}

@article{suwajanakorn_synthesizing_2017,
	title = {Synthesizing {Obama}: learning lip sync from audio},
	volume = {36},
	issn = {07300301},
	shorttitle = {Synthesizing {Obama}},
	url = {http://dl.acm.org/citation.cfm?doid=3072959.3073640},
	doi = {10.1145/3072959.3073640},
	language = {en},
	number = {4},
	urldate = {2019-07-18},
	journal = {ACM Transactions on Graphics},
	author = {Suwajanakorn, Supasorn and Seitz, Steven M. and Kemelmacher-Shlizerman, Ira},
	month = jul,
	year = {2017},
	pages = {1--13},
	file = {Suwajanakorn et al. - 2017 - Synthesizing Obama learning lip sync from audio.pdf:/home/lauga/Zotero/storage/UEMD92YJ/Suwajanakorn et al. - 2017 - Synthesizing Obama learning lip sync from audio.pdf:application/pdf}
}

@misc{mordvintsev_inceptionism:_2015,
	title = {Inceptionism: {Going} {Deeper} into {Neural} {Networks}},
	shorttitle = {Inceptionism},
	url = {http://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html},
	abstract = {Posted by Alexander Mordvintsev, Software Engineer, Christopher Olah, Software Engineering Intern and Mike Tyka, Software Engineer Update - ...},
	language = {en},
	urldate = {2019-07-18},
	journal = {Google AI Blog},
	author = {Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
	month = jun,
	year = {2015},
	file = {Snapshot:/home/lauga/Zotero/storage/ZY5K3CW5/inceptionism-going-deeper-into-neural.html:text/html}
}

@book{sumner_folkways_1906,
	title = {Folkways, a study of the sociological importance of usages, manners, customs, mores, and morals},
	url = {http://archive.org/details/folkwaysstudyofs00sumnuoft},
	abstract = {Bibliographical footnotes; 26},
	language = {eng},
	urldate = {2019-07-18},
	publisher = {Boston, Ginn},
	author = {Sumner, William Graham},
	collaborator = {{Robarts - University of Toronto}},
	year = {1906},
	keywords = {Manners and customs}
}

@book{nietzsche_genealogie_1900,
	title = {La {Généalogie} de la morale},
	volume = {Œuvres complètes de Frédéric Nietzsche, vol. 11},
	url = {https://fr.wikisource.org/wiki/La_G%C3%A9n%C3%A9alogie_de_la_morale/Premi%C3%A8re_dissertation},
	publisher = {Mercure de France},
	author = {Nietzsche, Friedrich},
	year = {1900}
}

@book{villani_donner_2018,
	title = {Donner un sens à l'intelligence artificielle: pour une stratégie nationale européenne : [{Mission} parlementaire du 8 septembre 2017 au 8 mars 2018},
	isbn = {978-2-11-145700-3},
	shorttitle = {Donner un sens à l'intelligence artificielle},
	abstract = {La 4e de couverture indique : "L'intelligence artificielle est entrée, depuis quelques années, dans une nouvelle ère, qui donne lieu à de nombreuses craintes et à de nombreux espoirs. Rendues possibles par des algorithmes nouveaux, la multiplication des jeux de données et le décuplement des puissances de calcul, les applications se multiplient : traduction automatique, conduite autonome, détection de cancer... Le développement de l'intelligence artificielle est amené à toucher l'ensemble des domaines et des secteurs. Les investissements dans la recherche et dans l'industrie atteignent des sommes extraordinaires, notamment aux États-Unis et en Chine. Les responsables politiques du monde entier l'évoquent dans les discours de politique générale comme un levier de pouvoir majeur. C'est que l'intelligence artificielle va désormais jouer un rôle bien plus important que celui qu'elle jouait jusqu'alors et, plus que jamais, il nous faut donner un sens à son développement. Donner un sens, c'est d'abord donner une direction, un cap, pour positionner la France et l'Europe à l'avant-garde de cette révolution naissante. C'est également lui donner une signification : l'intelligence artificielle n'a précisément de sens que si elle participe du progrès humain, social et environnemental. Dans un monde marqué par les inégalités, elle ne doit pas conduire à renforcer les phénomènes d'exclusion et la concentration de la valeur. Donner un sens, c'est enfin expliquer : démystifier ces technologies auprès de la société, mais aussi expliquer l'intelligence artificielle en elle-même, s'agissant de techniques qui restent empreintes d'une très forte opacité. Donner un sens à l'IA, voilà donc l'objectif de ce rapport."},
	language = {French},
	author = {Villani, Cédric},
	year = {2018},
	note = {OCLC: 1030337149}
}

@phdthesis{tran_selection_2017,
	type = {Artificial {Intelligence} [cs.{AI}]},
	title = {Selection {Bias} {Correction} in {Supervised} {Learning} with {Importance} {Weight}},
	url = {https://tel.archives-ouvertes.fr/tel-01661470},
	abstract = {In the theory of supervised learning, the identical assumption, i.e. the training and test samples are drawn from the same probability distribution, plays a crucial role. Unfortunately, this essential assumption is often violated in the presence of selection bias. Under such condition, the standard supervised learning frameworks may suffer a significant bias. In this thesis, we address the problem of selection bias in supervised learning using the importance weighting method. We first introduce the supervised learning frameworks and discuss the importance of the identical assumption. We then study the importance weighting framework for generative and discriminative learning under a general selection scheme and investigate the potential of Bayesian Network to encode the researcher's a priori assumption about the relationships between the variables, including the selection variable, and to infer the independence and conditional independence relationships that allow selection bias to be corrected.We pay special attention to covariate shift, i.e. a special class of selection bias where the conditional distribution P(y{\textbar}x) of the training and test data are the same. We propose two methods to improve importance weighting for covariate shift. We first show that the unweighted model is locally less biased than the weighted one on low importance instances, and then propose a method combining the weighted and the unweighted models in order to improve the predictive performance in the target domain. Finally, we investigate the relationship between covariate shift and the missing data problem for data sets with small sample sizes and study a method that uses missing data imputation techniques to correct the covariate shift in simple but realistic scenarios},
	language = {en},
	urldate = {2019-07-18},
	school = {Université de Lyon},
	author = {Tran, Van-Tinh},
	month = jul,
	year = {2017},
	file = {Full Text PDF:/home/lauga/Zotero/storage/I3ENS85D/Tran - 2017 - Selection Bias Correction in Supervised Learning w.pdf:application/pdf;Snapshot:/home/lauga/Zotero/storage/YJGMW3LZ/tel-01661470.html:text/html}
}

@article{tual_peine_2016,
	title = {A peine lancée, une intelligence artificielle de {Microsoft} dérape sur {Twitter}},
	url = {https://www.lemonde.fr/pixels/article/2016/03/24/a-peine-lancee-une-intelligence-artificielle-de-microsoft-derape-sur-twitter_4889661_4408996.html},
	abstract = {L’entreprise américaine a lancé Tay, un « chatbot » censé discuter avec des adolescents sur les réseaux sociaux. Mais des propos racistes se sont glissés dans ces échanges.},
	language = {fr},
	urldate = {2019-07-18},
	journal = {Le Monde.fr},
	author = {Tual, Morgane},
	month = mar,
	year = {2016},
	file = {Snapshot:/home/lauga/Zotero/storage/CDRK5MN7/a-peine-lancee-une-intelligence-artificielle-de-microsoft-derape-sur-twitter_4889661_4408996.html:text/html}
}

@article{radford_language_2019,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	year = {2019},
	pages = {24},
	file = {Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:/home/lauga/Zotero/storage/F8G62URF/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:application/pdf}
}

@misc{rahwan_moral_2017,
	title = {Moral {Machine}},
	url = {http://moralmachine.mit.edu},
	abstract = {A platform for public participation in and discussion of the human perspective on machine-made moral decisions},
	urldate = {2019-07-18},
	journal = {Moral Machine},
	author = {Rahwan, Iyad and Bonnefon, Jean-François and Shariff, Azim},
	year = {2017},
	file = {Snapshot:/home/lauga/Zotero/storage/2VTUMZKV/moralmachine.mit.edu.html:text/html}
}

@article{shepardson_waymo_2018,
	title = {Waymo gets first {California} {OK} for driverless testing without...},
	url = {https://in.reuters.com/article/us-autos-selfdriving-waymo-idINKCN1N42S1},
	abstract = {Alphabet Inc's Waymo unit on Tuesday became the first company to receive a ...},
	language = {en},
	urldate = {2019-07-18},
	journal = {Reuters},
	author = {Shepardson, David and Sage, Alexandria},
	month = oct,
	year = {2018},
	keywords = {Arizona, Auto and Truck Manufacturers (TRBC), Automobiles / Auto Parts (Legacy), Automobiles and Auto Parts (TRBC), AUTOS, California, Company News, Computer and Electronics Retailers (TRBC), Europe, Germany, Pictures, Products / Services, Regulation, SELFDRIVING, Software (TRBC), Technology (TRBC), Transportation (TRBC), United States, US, WAYMO, Western Europe},
	file = {Snapshot:/home/lauga/Zotero/storage/IBLYU9QX/waymo-gets-first-california-ok-for-driverless-testing-without-backup-driver-idINKCN1N42S1.html:text/html}
}

@article{simpson_interpretation_1951,
	title = {The {Interpretation} of {Interaction} in {Contingency} {Tables}},
	volume = {13},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2984065},
	abstract = {The definition of second order interaction in a (2 × 2 × 2) table given by Bartlett is accepted, but it is shown by an example that the vanishing of this second order interaction does not necessarily justify the mechanical procedure of forming the three component 2 × 2 tables and testing each of these for significance by standard methods.},
	number = {2},
	urldate = {2019-07-18},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Simpson, E. H.},
	year = {1951},
	pages = {238--241}
}

@incollection{shapley_17._1953,
	address = {Princeton},
	title = {17. {A} {Value} for n-{Person} {Games}},
	volume = {2},
	isbn = {978-1-4008-8197-0},
	url = {https://www.degruyter.com/view/books/9781400881970/9781400881970-018/9781400881970-018.xml},
	urldate = {2019-07-18},
	booktitle = {Contributions to the {Theory} of {Games} ({AM}-28), {Volume} {II}},
	publisher = {Princeton University Press},
	author = {Shapley, L. S.},
	year = {1953},
	doi = {10.1515/9781400881970-018}
}

@article{morley_what_2019,
	title = {From {What} to {How}: {An} {Initial} {Review} of {Publicly} {Available} {AI} {Ethics} {Tools}, {Methods} and {Research} to {Translate} {Principles} into {Practices}},
	shorttitle = {From {What} to {How}},
	url = {http://arxiv.org/abs/1905.06876},
	abstract = {The debate about the ethical implications of Artificial Intelligence dates from the 1960s. However, in recent years symbolic AI has been complemented and sometimes replaced by Neural Networks and Machine Learning techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such debate has primarily focused on principles - the what of AI ethics - rather than on practices, the how. Awareness of the potential issues is increasing at a fast rate, but the AI community's ability to take action to mitigate the associated risks is still at its infancy. Therefore, our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs.},
	urldate = {2019-10-23},
	journal = {arXiv:1905.06876 [cs]},
	author = {Morley, Jessica and Floridi, Luciano and Kinsey, Libby and Elhalal, Anat},
	month = sep,
	year = {2019},
	note = {arXiv: 1905.06876},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computers and Society},
	annote = {Comment: 15 pages, links to typology available on the web},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/9YSBKXG2/Morley et al. - 2019 - From What to How An Initial Review of Publicly Av.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/M53U2VSE/1905.html:text/html}
}

@misc{peters_beyond_2019,
	title = {Beyond {Principles}: {A} {Process} for {Responsible} {Tech}},
	shorttitle = {Beyond {Principles}},
	url = {https://medium.com/ethics-of-digital-experience/beyond-principles-a-process-for-responsible-tech-aefc921f7317},
	abstract = {Meet the new design process: An upgrade with ethics \& digital wellbeing baked in.},
	language = {en},
	urldate = {2019-10-24},
	journal = {Medium},
	author = {Peters, Dorian},
	month = may,
	year = {2019}
}

@misc{miller_people_2019,
	title = {People, {Power} and {Technology}: {The} {Tech} {Workers}' {View} {\textbar} doteveryone},
	shorttitle = {People, {Power} and {Technology}},
	url = {https://doteveryone.org.uk/report/workersview/},
	abstract = {, The first in-depth research into the attitudes of the people who design and build digital technologies in the UK. It shows that workers are calling for an end to the era of moving fast and breaking things.},
	language = {en-US},
	urldate = {2019-10-24},
	author = {Miller, Catherine and Coldicutt, Rachel},
	year = {2019},
	file = {Snapshot:/home/lauga/Zotero/storage/KLN9ICAP/workersview.html:text/html}
}

@book{wiener_cybernetics;_1961,
	address = {New York},
	title = {Cybernetics; or, {Control} and communication in the animal and the machine.},
	isbn = {978-0-262-23007-0 978-0-262-73009-9},
	abstract = {Acclaimed one of the "seminal books ... comparable in ultimate importance to ... Galileo or Malthus or Rousseau or Mill", Cybernetics was judged by twenty-seven historians, economists, educators, and philosophers to be one of those books published during the "past four decades," which may have a substantial impact on public thought and action in the years ahead."--Saturday Review.},
	language = {English},
	publisher = {M.I.T. Press},
	author = {Wiener, Norbert},
	year = {1961},
	note = {OCLC: 1284210}
}

@misc{noauthor_declaration_nodate,
	title = {La {Déclaration} de {Montréal} en {IA} responsable},
	url = {https://www.declarationmontreal-iaresponsable.com/la-declaration},
	abstract = {Déclaration {\textbar} Déclaration de Montréal {\textbar} Intelligence artificielle responsable},
	language = {fr},
	urldate = {2019-10-25},
	journal = {declarationiaresp},
	file = {Snapshot:/home/lauga/Zotero/storage/RZQWIDQN/la-declaration.html:text/html}
}

@misc{noauthor_ethically_nodate,
	title = {Ethically {Aligned} {Design}, {First} {Edition} {\textbar} {IEEE} {Standards} {Association}},
	url = {https://ethicsinaction.ieee.org/},
	abstract = {The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems is launching the Ethically Aligned Design, First Edition.},
	language = {en-US},
	urldate = {2019-10-25},
	journal = {Ethically Aligned Design - IEEE},
	file = {Snapshot:/home/lauga/Zotero/storage/FHY8N7BQ/ethicsinaction.ieee.org.html:text/html}
}

@article{turilli_ethical_2007,
	title = {Ethical protocols design},
	volume = {9},
	issn = {1572-8439},
	url = {https://doi.org/10.1007/s10676-006-9128-9},
	doi = {10.1007/s10676-006-9128-9},
	abstract = {The paper offers a solution to the problem of specifying computational systems that behave in accordance with a given set of ethical principles. The proposed solution is based on the concepts of ethical requirements and ethical protocols. A new conceptual tool, called the Control Closure of an operation, is defined and used to translate ethical principles into ethical requirements and protocols. The concept of Generalised Informational Privacy (GIP) is used as a paradigmatic example of an ethical principle. GIP is defined in such a way as to (i) discriminate specific cases in which an individual’s GIP can be infringed without accessing the individual’s data; (ii) separate unauthorised accesses to data that do not respect the right to GIP from access that do; and (iii) distinguish different degrees of GIP. Finally a camera phone is used to illustrate the proposed solution.},
	language = {en},
	number = {1},
	urldate = {2019-10-31},
	journal = {Ethics and Information Technology},
	author = {Turilli, Matteo},
	month = mar,
	year = {2007},
	keywords = {ethical protocols, ethical requirements, informational privacy, protocols design, system specification},
	pages = {49--62}
}

@article{rawbone_principles_2014,
	title = {Principles of {Biomedical} {Ethics}, 7th {Edition}},
	volume = {65},
	issn = {0962-7480},
	url = {https://doi.org/10.1093/occmed/kqu158},
	doi = {10.1093/occmed/kqu158},
	abstract = {This book has to be one of the most important and influential books in the field of bioethics. Now in its seventh edition, over the past 35 years, the authors have tried to keep the text up to date with developments in the field; strengthening their arguments, addressing issues raised by critics and taking account of newly published material on the topics covered. In this, the authors have been largely successful and although the book follows the basic structure of the sixth edition, the revisions are not insignificant.The book is set out in three parts. In Part I, ‘Moral Foundations’, the authors consider what constitutes moral character and address the problem of moral status. Part II, ‘Moral Principles’, argues for and thoroughly develops four principles at the core of moral reasoning in health care: respect for autonomy, non-maleficence, beneficence, and justice. Finally, Part III, ‘Theory and Method’, surveys major philosophical theories in biomedical ethics.},
	number = {1},
	urldate = {2019-01-11},
	journal = {Occupational Medicine},
	author = {Rawbone, Roger},
	month = dec,
	year = {2014},
	pages = {88--89}
}

@misc{mishra_metrics_2018,
	title = {Metrics to {Evaluate} your {Machine} {Learning} {Algorithm}},
	url = {https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234},
	abstract = {Evaluating your machine learning algorithm is an essential part of any project. Your model may give you satisfying results when evaluated…},
	language = {en},
	urldate = {2019-11-04},
	journal = {Medium},
	author = {Mishra, Aditya},
	month = nov,
	year = {2018},
	file = {Snapshot:/home/lauga/Zotero/storage/88IJS6IP/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234.html:text/html}
}

@article{rauber_foolbox:_2018,
	title = {Foolbox: {A} {Python} toolbox to benchmark the robustness of machine learning models},
	shorttitle = {Foolbox},
	url = {http://arxiv.org/abs/1707.04131},
	abstract = {Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox . The most up-to-date documentation can be found at http://foolbox.readthedocs.io .},
	urldate = {2019-11-04},
	journal = {arXiv:1707.04131 [cs, stat]},
	author = {Rauber, Jonas and Brendel, Wieland and Bethge, Matthias},
	month = mar,
	year = {2018},
	note = {arXiv: 1707.04131},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
	annote = {Comment: Code and examples available at https://github.com/bethgelab/foolbox and documentation available at http://foolbox.readthedocs.io},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/J8K9KY9X/Rauber et al. - 2018 - Foolbox A Python toolbox to benchmark the robustn.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/JSTVW6M2/1707.html:text/html}
}

@article{nicolae_adversarial_2019,
	title = {Adversarial {Robustness} {Toolbox} v0.4.0},
	url = {http://arxiv.org/abs/1807.01069},
	abstract = {Adversarial examples have become an indisputable threat to the security of modern AI systems based on deep neural networks (DNNs). The Adversarial Robustness Toolbox (ART) is a Python library designed to support researchers and developers in creating novel defence techniques, as well as in deploying practical defences of real-world AI systems. Researchers can use ART to benchmark novel defences against the state-of-the-art. For developers, the library provides interfaces which support the composition of comprehensive defence systems using individual methods as building blocks. The Adversarial Robustness Toolbox supports machine learning models (and deep neural networks (DNNs) specifically) implemented in any of the most popular deep learning frameworks (TensorFlow, Keras, PyTorch and MXNet). Currently, the library is primarily intended to improve the adversarial robustness of visual recognition systems, however, future releases that will comprise adaptations to other data modes (such as speech, text or time series) are envisioned. The ART source code is released (https://github.com/IBM/adversarial-robustness-toolbox) under an MIT license. The release includes code examples and extensive documentation (http://adversarial-robustness-toolbox.readthedocs.io) to help researchers and developers get quickly started.},
	urldate = {2019-11-04},
	journal = {arXiv:1807.01069 [cs, stat]},
	author = {Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh Ngoc and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and Molloy, Ian M. and Edwards, Ben},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.01069},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 41 pages},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/KBKMJXRS/Nicolae et al. - 2019 - Adversarial Robustness Toolbox v0.4.0.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/SAUQ2V9D/1807.html:text/html}
}

@article{papernot_technical_2018,
	title = {Technical {Report} on the {CleverHans} v2.1.0 {Adversarial} {Examples} {Library}},
	url = {http://arxiv.org/abs/1610.00768},
	abstract = {CleverHans is a software library that provides standardized reference implementations of adversarial example construction techniques and adversarial training. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models' performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section 1 provides an overview of adversarial examples in machine learning and of the CleverHans software. Section 2 presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section 3 describes how to report benchmark results using the library. Section 4 describes the versioning system.},
	urldate = {2019-11-04},
	journal = {arXiv:1610.00768 [cs, stat]},
	author = {Papernot, Nicolas and Faghri, Fartash and Carlini, Nicholas and Goodfellow, Ian and Feinman, Reuben and Kurakin, Alexey and Xie, Cihang and Sharma, Yash and Brown, Tom and Roy, Aurko and Matyasko, Alexander and Behzadan, Vahid and Hambardzumyan, Karen and Zhang, Zhishuai and Juang, Yi-Lin and Li, Zhi and Sheatsley, Ryan and Garg, Abhibhav and Uesato, Jonathan and Gierke, Willi and Dong, Yinpeng and Berthelot, David and Hendricks, Paul and Rauber, Jonas and Long, Rujun and McDaniel, Patrick},
	month = jun,
	year = {2018},
	note = {arXiv: 1610.00768},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment: Technical report for https://github.com/tensorflow/cleverhans},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/U5V5X56X/Papernot et al. - 2018 - Technical Report on the CleverHans v2.1.0 Adversar.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/NQFQ85NS/1610.html:text/html}
}

@article{ribeiro_why_2016,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2019-11-04},
	journal = {arXiv:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	note = {arXiv: 1602.04938},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/lauga/Zotero/storage/27TGNMVF/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf;arXiv.org Snapshot:/home/lauga/Zotero/storage/LHEWZYJW/1602.html:text/html}
}

@misc{columbus_25_2019,
	title = {25 {Machine} {Learning} {Startups} {To} {Watch} {In} 2019},
	url = {https://www.forbes.com/sites/louiscolumbus/2019/05/27/25-machine-learning-startups-to-watch-in-2019/},
	abstract = {Artificial intelligence deals increased in Q1, 2019 to 116 deals, up from 104 deals in Q4, 2018 according to the latest PwC/CB Insights MoneyTree Report Q1 2019.},
	language = {en},
	urldate = {2020-03-21},
	journal = {Forbes},
	author = {Columbus, Louis},
	month = may,
	year = {2019},
	note = {Library Catalog: www.forbes.com
Section: Innovation},
	file = {Snapshot:/home/lauga/Zotero/storage/U8T4M3FQ/25-machine-learning-startups-to-watch-in-2019.html:text/html}
}

@misc{noauthor_alphago_2017,
	title = {{AlphaGo}, l'ordinateur prodige au jeu de go, prend sa retraite},
	url = {https://www.sciencesetavenir.fr/sciences/alphago-l-ordinateur-prodige-au-jeu-de-go-prend-sa-retraite_113277},
	abstract = {Le joueur de go sud-coréen Lee Se-Dol opposé à l'ordinateur AlphaGo, à Séoul, le 12 mars 2016-GOOGLE DEEPMIND/AFP/Archives/Handout Le superordinateur},
	language = {fr},
	urldate = {2020-03-21},
	journal = {Sciences et Avenir},
	month = may,
	year = {2017},
	note = {Library Catalog: www.sciencesetavenir.fr},
	file = {Snapshot:/home/lauga/Zotero/storage/4QFBBIIC/alphago-l-ordinateur-prodige-au-jeu-de-go-prend-sa-retraite_113277.html:text/html}
}



@misc{haupt_who_2006,
	title = {Who should get credit for the quote 'data is the new oil'? - {Quora}},
	url = {https://www.quora.com/Who-should-get-credit-for-the-quote-data-is-the-new-oil},
	urldate = {2020-03-22},
	journal = {Quora},
	author = {Haupt, Michael},
	year = {2006},
	file = {Who should get credit for the quote 'data is the new oil'? - Quora:/home/lauga/Zotero/storage/23Q254H4/Who-should-get-credit-for-the-quote-data-is-the-new-oil.html:text/html}
}


@article{moore_cramming_1998,
	title = {Cramming {More} {Components} {Onto} {Integrated} {Circuits}},
	volume = {86},
	issn = {0018-9219, 1558-2256},
	url = {http://ieeexplore.ieee.org/document/658762/},
	doi = {10.1109/JPROC.1998.658762},
	language = {en},
	number = {1},
	urldate = {2020-03-23},
	journal = {Proceedings of the IEEE},
	author = {Moore, G.E.},
	month = jan,
	year = {1998},
	pages = {82--85},
	file = {Moore - 1998 - Cramming More Components Onto Integrated Circuits.pdf:/home/lauga/Zotero/storage/U2P9IIML/Moore - 1998 - Cramming More Components Onto Integrated Circuits.pdf:application/pdf}
}

@article{reinsel_digitization_2018,
	title = {The {Digitization} of the {World} from {Edge} to {Core}},
	url = {https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf},
	language = {en},
	author = {Reinsel, David and Gantz, John and Rydning, John},
	month = nov,
	year = {2018},
	pages = {28},
	file = {Reinsel et al. - 2018 - The Digitization of the World from Edge to Core.pdf:/home/lauga/Zotero/storage/258JGW66/Reinsel et al. - 2018 - The Digitization of the World from Edge to Core.pdf:application/pdf}
}

@misc{desjardins_what_2019,
	title = {What {Happens} in an {Internet} {Minute} in 2019?},
	url = {https://www.visualcapitalist.com/what-happens-in-an-internet-minute-in-2019/},
	abstract = {In every internet minute, there is an extraordinary amount of activity. Wrap your head around it all with this nifty infographic.},
	language = {en-US},
	urldate = {2020-03-23},
	journal = {Visual Capitalist},
	author = {Desjardins, Jeff},
	month = mar,
	year = {2019},
	note = {Library Catalog: www.visualcapitalist.com},
	file = {Snapshot:/home/lauga/Zotero/storage/NTL5TBRN/what-happens-in-an-internet-minute-in-2019.html:text/html}
}

@misc{figure_eight_state_2019,
	title = {The {State} of {AI} and {Machine} {Learning} {Report}},
	url = {https://www.figure-eight.com/the-state-of-ai-and-machine-learning-report/},
	abstract = {Download Figure Eight's State of AI and Machine Learning Report explores the AI gap between data scientist and line-of-business owners.},
	language = {en-US},
	urldate = {2020-03-28},
	journal = {Figure Eight},
	author = {Figure\_Eight},
	month = may,
	year = {2019},
	note = {Library Catalog: www.figure-eight.com
Section: eBooks},
	file = {Snapshot:/home/lauga/Zotero/storage/5SCZZWUK/the-state-of-ai-and-machine-learning-report.html:text/html}
}


@misc{russell_interview_2019,
	title = {An interview with {Dr}. {Stuart} {Russell}, author of ‘{Human} {Compatible}, {Artificial} {Intelligence} and the {Problem} of {Control}’},
	url = {http://social.techcrunch.com/2019/10/06/an-interview-with-dr-stuart-russell-author-of-human-compatible-artificial-intelligence-and-the-problem-of-control/},
	abstract = {(UC Berkeley’s Dr. Stuart Russell’s new book, “Human Compatible: Artificial Intelligence and the Problem of Control, goes on sale Oct. 8. I’ve written a review, “Human Compatible” is a provocative prescription to re-think AI before it’s too late,” and…},
	language = {en-US},
	urldate = {2020-03-31},
	journal = {TechCrunch},
	author = {Russell, Stuart},
	month = oct,
	year = {2019},
	note = {Library Catalog: techcrunch.com},
	file = {Snapshot:/home/lauga/Zotero/storage/ECMEMHRG/an-interview-with-dr-stuart-russell-author-of-human-compatible-artificial-intelligence-and-the-.html:text/html}
}

@misc{ege_ethics_2018,
	type = {Text},
	title = {Ethics of {Artificial} {Intelligence}: {Statement} of the {EGE} is released},
	shorttitle = {Ethics of {Artificial} {Intelligence}},
	url = {https://ec.europa.eu/info/news/ethics-artificial-intelligence-statement-ege-released-2018-apr-24_en},
	abstract = {EGE statement on Artificial Intelligence},
	language = {en},
	urldate = {2020-04-05},
	journal = {European Commission - European Commission},
	author = {{EGE}},
	month = mar,
	year = {2018},
	note = {Library Catalog: ec.europa.eu},
	file = {Snapshot:/home/lauga/Zotero/storage/CI6GBMFE/ethics-artificial-intelligence-statement-ege-released-2018-apr-24_en.html:text/html}
}

@misc{universite_de_montreal_declaration_2017,
	title = {La {Déclaration} de {Montréal} en {IA} responsable},
	url = {https://www.declarationmontreal-iaresponsable.com/la-declaration},
	abstract = {Déclaration {\textbar} Déclaration de Montréal {\textbar} Intelligence artificielle responsable},
	language = {fr},
	urldate = {2019-10-25},
	journal = {declarationiaresp},
	author = {{Université de Montréal}},
	month = nov,
	year = {2017},
	file = {Snapshot:/home/lauga/Zotero/storage/RZQWIDQN/la-declaration.html:text/html}
}


@misc{uk_parliament_house_2017,
	title = {House of {Lords} - {AI} in the {UK}: ready, willing and able? - {Artificial} {Intelligence} {Committee}},
	url = {https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/10002.htm},
	urldate = {2020-04-05},
	author = {{UK Parliament}},
	month = apr,
	year = {2017},
	file = {House of Lords - AI in the UK\: ready, willing and able? - Artificial Intelligence Committee:/home/lauga/Zotero/storage/SDAK7LUA/10002.html:text/html}
}

@book{jackson_introduction_1998,
	address = {USA},
	edition = {3rd},
	title = {Introduction to {Expert} {Systems}},
	isbn = {978-0-201-87686-4},
	abstract = {From the Publisher: The third edition of Peter Jackson's book, Introduction to Expert Systems, updates the technological base of expert systems research and embeds those results in the context of a wide variety of application areas. The earlier chapters take a more practical approach to the basic topics than the previous editions, while the later chapters introduce new topic areas, such as case-based reasoning, connectionist systems, and hybrid systems. Results in related areas, such as machine learning and reasoning with uncertainty are also accorded a thorough treatment.},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Jackson, Peter},
	year = {1998}
}


@misc{cambridge_data_2020,
	title = {{DATA} {\textbar} signification, définition dans le dictionnaire {Anglais} de {Cambridge}},
	url = {https://dictionary.cambridge.org/fr/dictionnaire/anglais/data},
	abstract = {data définition, signification, ce qu'est data: 1. information, especially facts or numbers, collected to be examined and considered and used to…. En savoir plus.},
	language = {fr},
	urldate = {2020-04-20},
	author = {{Cambridge}},
	year = {2020},
	note = {Library Catalog: dictionary.cambridge.org},
	file = {Snapshot:/home/lauga/Zotero/storage/6FZDCU3E/data.html:text/html}
}

@misc{press_very_2013,
	title = {A {Very} {Short} {History} {Of} {Big} {Data}},
	url = {https://www.forbes.com/sites/gilpress/2013/05/09/a-very-short-history-of-big-data/},
	abstract = {The story of how data became big starts many years before the current buzz around big data. Already seventy years ago we encounter the first attempts to quantify the growth rate in the volume of data or what has popularly been known as the “information explosion” (a term first used in 1941, [...]},
	language = {en},
	urldate = {2020-04-20},
	journal = {Forbes},
	author = {Press, Gil},
	month = may,
	year = {2013},
	note = {Library Catalog: www.forbes.com
Section: Innovation},
	file = {Snapshot:/home/lauga/Zotero/storage/I3THMS4E/a-very-short-history-of-big-data.html:text/html}
}

@book{kasparov_deep_2017,
	title = {Deep {Thinking}: {Where} {Machine} {Intelligence} {Ends} and {Human} {Creativity} {Begins}},
	isbn = {978-1-4736-5350-4},
	shorttitle = {Deep {Thinking}},
	abstract = {In May 1997, the world watched as Garry Kasparov, the greatest chess player in the world, was defeated for the first time by the IBM supercomputer Deep Blue. It was a watershed moment in the history of technology: machine intelligence had arrived at the point where it could best human intellect.It wasn't a coincidence that Kasparov became the symbol of man's fight against the machines. Chess has long been the fulcrum in development of machine intelligence; the hoax automaton 'The Turk' in the 18th century and Alan Turing's first chess program in 1952 were two early examples of the quest for machines to think like humans -- a talent we measured by their ability to beat their creators at chess. As the pre-eminent chessmaster of the 80s and 90s, it was Kasparov's blessing and his curse to play against each generation's strongest computer champions, contributing to their development and advancing the field. Like all passionate competitors, Kasparov has taken his defeat and learned from it. He has devoted much energy to devising ways in which humans can partner with machines in order to produce results better than either can achieve alone. During the twenty years since playing Deep Blue, he's played both with and against machines, learning a great deal about our vital relationship with our most remarkable creations. Ultimately, he's become convinced that by embracing the competition between human and machine intelligence, we can spend less time worrying about being replaced and more thinking of new challenges to conquer.In this breakthrough book, Kasparov tells his side of the story of Deep Blue for the first time -- what it was like to strategize against an implacable, untiring opponent -- the mistakes he made and the reasons the odds were against him. But more than that, he tells his story of AI more generally, and how he's evolved to embrace it, taking part in an urgent debate with philosophers worried about human values, programmers creating self-learning neural networks, and engineers of cutting edge robotics.},
	language = {Anglais},
	publisher = {John Murray},
	author = {Kasparov, Garry},
	month = jun,
	year = {2017}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain.},
	volume = {65},
	issn = {1939-1471, 0033-295X},
	shorttitle = {The perceptron},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
	doi = {10.1037/h0042519},
	language = {en},
	number = {6},
	urldate = {2020-05-24},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	pages = {386--408},
	file = {Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf:/home/lauga/Zotero/storage/XIYFPZBT/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf:application/pdf}
}


@book{eden_singularity_2013,
	address = {New York},
	edition = {2012 edition},
	title = {Singularity {Hypotheses}: {A} {Scientific} and {Philosophical} {Assessment}},
	isbn = {978-3-642-32559-5},
	shorttitle = {Singularity {Hypotheses}},
	abstract = {Singularity Hypotheses: A Scientific and Philosophical Assessment offers authoritative, jargon-free essays and critical commentaries on accelerating technological progress and the notion of technological singularity. It focuses on conjectures about the intelligence explosion, transhumanism, and whole brain emulation. Recent years have seen a plethora of forecasts about the profound, disruptive impact that is likely to result from further progress in these areas. Many commentators however doubt the scientific rigor of these forecasts, rejecting them as speculative and unfounded. We therefore invited prominent computer scientists, physicists, philosophers, biologists, economists and other thinkers to assess the singularity hypotheses. Their contributions go beyond speculation, providing deep insights into the main issues and a balanced picture of the debate.},
	language = {English},
	publisher = {Springer},
	editor = {Eden, Amnon H. and Moor, James H. and Soraker, Johnny H. and Steinhart, Eric},
	month = apr,
	year = {2013}
}


@book{aristote_ethique_1994,
	edition = {Revised},
	title = {Ethique à {Nicomaque}},
	isbn = {978-2-7116-0022-9},
	abstract = {Tout art et toute investigation, et pareillement toute action et tout choix tendent vers quelque bien, a ce qu'il semble. Aussi a-t-on declare avec raison que le Bien est ce a quoi toutes choses tendent. Mais on observe, en fait, une certaine difference entre les fins: les unes consistent dans des activites, et les autres dans certaines oeuvres, distinctes des activites elles-memes. Et la ou existent certaines fins distinctes des actions, dans ces cas-la, les oeuvres sont par nature superieures aux activites qui les produisent. [...]. Si donc il y a, de nos activites, quelque fin que nous souhaitons par elle-meme, [...] il est clair que cette fin-la ne saurait etre que le bien, le Souverain Bien. .},
	language = {Français},
	publisher = {Vrin},
	author = {Aristote},
	month = jan,
	year = {1994}
}

@article{boas_museums_1887,
	title = {Museums of {Ethnology} and {Their} {Classification}},
	volume = {9},
	issn = {0036-8075},
	url = {https://www.jstor.org/stable/1762958},
	number = {228},
	urldate = {2020-06-01},
	journal = {Science},
	author = {Boas, Franz},
	year = {1887},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {587--589}
}

@book{servier_methode_1993,
	address = {Paris},
	edition = {2e éd. rev.},
	series = {Que sais-je ?},
	title = {Méthode de l'ethnologie},
	isbn = {978-2-13-045905-7},
	publisher = {PUF},
	author = {Servier, Jean},
	year = {1993}
}


@article{astuti_moralite_2007,
	title = {La moralité des conventions : tabous ancestraux à {Madagascar}},
	copyright = {Terrain est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d'Utilisation Commerciale - Pas de Modification 4.0 International.},
	issn = {0760-5668},
	shorttitle = {La moralité des conventions},
	url = {http://journals.openedition.org/terrain/5041},
	doi = {10.4000/terrain.5041},
	abstract = {Les Vezo de Madagascar sont tenus d’obéir à de multiples tabous ancestraux qui leur interdisent de consommer certains aliments, de proférer certains mots, de porter certains vêtements, de marcher dans certaines directions, d’être intimes avec certaines personnes. Pour eux, les activités prohibées par les tabous ne sont ni bonnes ni mauvaises en elles-mêmes. Et ils peuvent utiliser des rituels spécifiques, certes onéreux, pour lever un tabou devenu particulièrement lourd. Sous cet angle, les tabous vezo sont des normes conventionnelles. Toutefois, le fait de se plier à la volonté des ancêtres à l’origine des tabous constitue l’acte moral le plus distinctif accompli par les Vezo. Ces données ethnographiques sont utilisées dans cet article pour questionner la distinction entre morale et conventions.},
	language = {fr},
	number = {48},
	urldate = {2020-06-01},
	journal = {Terrain. Anthropologie \& sciences humaines},
	author = {Astuti, Rita},
	month = feb,
	year = {2007},
	note = {ISBN: 9782735111312
Number: 48
Publisher: Association Terrain},
	pages = {101--112},
	file = {Snapshot:/home/lauga/Zotero/storage/XARLHKUX/5041.html:text/html}
}

@book{redfield_primitive_1965,
	title = {The {Primitive} {World} and {Its} {Transformations}},
	language = {en},
	publisher = {Cornell University Press},
	author = {Redfield, Robert},
	year = {1965},
	note = {Google-Books-ID: KHQLAAAAYAAJ}
}

@book{montaigne_essais_1789,
	title = {Essais de {Montaigne}},
	language = {fr},
	publisher = {Volland},
	author = {Montaigne, Michel de},
	year = {1789},
	note = {Google-Books-ID: 5I0tAAAAMAAJ}
}

@book{rousseau_rousseau_1969,
	address = {Paris},
	title = {Rousseau : {Oeuvres} complètes, tome 4},
	isbn = {978-2-07-010491-8},
	shorttitle = {Rousseau},
	abstract = {On trouvera dans ce tome IV des Œuvres complètes ce qui formait, aux yeux de Rousseau, l'essentiel de sa pensée en matière d'éducation, comme aussi en matière d'anthropologie généraIe et de théologie. Le commentaire de ces textes capitaux a été confié à J. S. Spink, qui connut l'activité des pédagogues du XVIIIE siècle, à un grand historien des idées philosophiques, Henri Gouhier, et à l'auteur d'une thèse dès aujourd'hui classique sur la philosophie de l'existence de J.-J. Rousseau. Pierre Burgelin a analysé l'Émile, «l'une des œuvres clefs de notre civilisation», avec une force pénétrante qui en fait ressortir toute la richesse et l'originalité. On lira enfin, présentées par R. de Vilmorin, les Lettres sur la botanique, dont l'intention didactique est indiscutable. Des notices bibliographiques et un index des noms et des ouvrages cités dans ce volume complètent cet ensemble de textes et de notes critiques qui renouvellent notre connaissance de la pensée morale et religieuse de J.-J. Rousseau.},
	language = {Français},
	publisher = {Gallimard},
	author = {Rousseau, Jean-Jacques},
	month = apr,
	year = {1969}
}

@article{baumard_preschoolers_2012,
	title = {Preschoolers are able to take merit into account when distributing goods},
	volume = {48},
	issn = {1939-0599(Electronic),0012-1649(Print)},
	doi = {10.1037/a0026598},
	abstract = {Classic studies in developmental psychology demonstrate a relatively late development of equity, with children as old as 6 or even 8–10 years failing to follow the logic of merit—that is, giving more to those who contributed more. Following Piaget (1932), these studies have been taken to indicate that judgments of justice develop slowly and follow a stagelike progression, starting off with simple rules (e.g., equality: everyone receives the same) and only later on in development evolving into more complex ones (e.g., equity: distributions match contributions). Here, we report 2 experiments with 3- and 4-year-old children (N = 195) that contradict this constructivist account. Our results demonstrate that children as young as 3 years old are able to take merit into account by distributing tokens according to individual contributions but that this ability may be hidden by a preference for equality. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Developmental Psychology},
	author = {Baumard, Nicolas and Mascaro, Olivier and Chevallier, Coralie},
	year = {2012},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Childhood Development, Cooperation, Equity (Social), Fairness, Morality},
	pages = {492--498},
	file = {Snapshot:/home/lauga/Zotero/storage/59HQ4MP2/2011-28655-001.html:text/html}
}

@article{hamlin_social_2007,
	title = {Social evaluation by preverbal infants},
	volume = {450},
	issn = {1476-4687},
	doi = {10.1038/nature06288},
	abstract = {The capacity to evaluate other people is essential for navigating the social world. Humans must be able to assess the actions and intentions of the people around them, and make accurate decisions about who is friend and who is foe, who is an appropriate social partner and who is not. Indeed, all social animals benefit from the capacity to identify individual conspecifics that may help them, and to distinguish these individuals from others that may harm them. Human adults evaluate people rapidly and automatically on the basis of both behaviour and physical features, but the ontogenetic origins and development of this capacity are not well understood. Here we show that 6- and 10-month-old infants take into account an individual's actions towards others in evaluating that individual as appealing or aversive: infants prefer an individual who helps another to one who hinders another, prefer a helping individual to a neutral individual, and prefer a neutral individual to a hindering individual. These findings constitute evidence that preverbal infants assess individuals on the basis of their behaviour towards others. This capacity may serve as the foundation for moral thought and action, and its early developmental emergence supports the view that social evaluation is a biological adaptation.},
	language = {eng},
	number = {7169},
	journal = {Nature},
	author = {Hamlin, J. Kiley and Wynn, Karen and Bloom, Paul},
	month = nov,
	year = {2007},
	pmid = {18033298},
	keywords = {Choice Behavior, Communication, Connecticut, Cooperative Behavior, Humans, Infant, Learning, Parents, Photic Stimulation, Social Behavior, Time Factors},
	pages = {557--559}
}

@article{gurven_give_2004,
	title = {To give and to give not: {The} behavioral ecology of human food transfers},
	volume = {27},
	shorttitle = {To give and to give not},
	doi = {10.1017/S0140525X04000123},
	abstract = {The transfer of food among group members is a ubiquitous feature of small-scale forager and forager-agricultural populations. The uniqueness of pervasive sharing among humans, especially among unrelated individuals, has led researchers to evaluate numerous hypotheses about the adaptive functions and patterns of sharing in different ecologies. This article attempts to organize available cross-cultural evidence pertaining to several contentious evolutionary models: kin selection, reciprocal altruism, tolerated scrounging, and costly signaling. Debates about the relevance of these models focus primarily on the extent to which individuals exert control over the distribution of foods they acquire, and the extent to which donors receive food or other fitness-enhancing benefits in return for shares given away. Each model can explain some of the variance in sharing patterns within groups, and so generalizations that ignore or deny the importance of any one model may be misleading. Careful multivariate analyses and cross-cultural comparisons of food transfer patterns are therefore necessary tools for assessing aspects of the sexual division of labor, human life history evolution, and the evolution of the family. This article also introduces a framework for better understanding variation in sharing behavior across small-scale traditional societies. I discuss the importance of resource ecology and the degree of coordination in acquisition activities as a key feature that influences sharing behavior.},
	journal = {Behavioral and Brain Sciences - BEHAV BRAIN SCI},
	author = {Gurven, Michael},
	month = aug,
	year = {2004},
	file = {Full Text PDF:/home/lauga/Zotero/storage/U5UX3KAT/Gurven - 2004 - To give and to give not The behavioral ecology of.pdf:application/pdf}
}

@article{bouchard_genetic_2003,
	title = {Genetic and environmental influences on human psychological differences},
	volume = {54},
	issn = {0022-3034},
	doi = {10.1002/neu.10160},
	abstract = {Psychological researchers typically distinguish five major domains of individual differences in human behavior: cognitive abilities, personality, social attitudes, psychological interests, and psychopathology (Lubinski, 2000). In this article we: discuss a number of methodological errors commonly found in research on human individual differences; introduce a broad framework for interpreting findings from contemporary behavioral genetic studies; briefly outline the basic quantitative methods used in human behavioral genetic research; review the major criticisms of behavior genetic designs, with particular emphasis on the twin and adoption methods; describe the major or dominant theoretical scheme in each domain; and review behavioral genetic findings in all five domains. We conclude that there is now strong evidence that virtually all individual psychological differences, when reliably measured, are moderately to substantially heritable.},
	language = {eng},
	number = {1},
	journal = {Journal of Neurobiology},
	author = {Bouchard, Thomas J. and McGue, Matt},
	month = jan,
	year = {2003},
	pmid = {12486697},
	keywords = {Adoption, Age Factors, Attitude, Cognition, Data Interpretation, Statistical, Family Relations, Female, Genetics, Behavioral, Humans, Individuality, Intelligence Tests, Learning, Male, Mental Disorders, Personality, Religion, Sex Characteristics, Social Environment, Statistics as Topic, Twin Studies as Topic, Twins, Work},
	pages = {4--45}
}

@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@misc{commission_europeenne_ethics_2019,
	type = {Text},
	title = {Ethics guidelines for trustworthy {AI}},
	url = {https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai},
	abstract = {On 8 April 2019, the High-Level Expert Group on AI presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
	language = {en},
	urldate = {2019-11-01},
	journal = {Digital Single Market - European Commission},
	author = {UE Commission},
	month = apr,
	year = {2019},
	file = {Snapshot:/home/lauga/Zotero/storage/QHKNPSVD/ethics-guidelines-trustworthy-ai.html:text/html}
}

@misc{algorithm_watch_ai_2020,
	title = {{AI} {Ethics} {Guidelines} {Global} {Inventory} by {AlgorithmWatch}},
	url = {https://inventory.algorithmwatch.org},
	abstract = {AI Ethics Guidelines Global Inventory, a project by AlgorithmWatch that maps frameworks that seek to set out principles of how systems for automated decision-making (ADM) can be developed and implemented ethically. Browse through the inventory using the new filters and search feature! Last update: M},
	language = {de-DE},
	urldate = {2020-06-04},
	journal = {AI Ethics Guidelines Global Inventory},
	author = {{Algorithm Watch}},
	month = apr,
	year = {2020},
	note = {Library Catalog: inventory.algorithmwatch.org},
	file = {Snapshot:/home/lauga/Zotero/storage/IHAVYD67/inventory.algorithmwatch.org.html:text/html}
}

@book{grinbaum_les_2019,
	title = {Les robots et le mal},
	isbn = {978-2-220-09594-3},
	abstract = {Des robots domestiques se fontdélateurs, des agents conversationnels injurient leurs interlocuteurs. Pireencore : des systèmes informatiques participent aux conflits humains etparfois même les provoquent. Le 18 mars 2018, un véhicule autonome dela société Uber a tué une femme qui traversait la rue dans une ville del'Arizona. Ce fut la première mort d'un piéton provoquée par un algorithme.Qui est responsable ? Laréponse à cette question compte parmi les défis les plus urgents à relever dansnotre rapport aux technologies numériques. Mais il ne s'agit pas de savoircomment rendre l'intelligence artificielle bienveillante. Il s'agit de faire ensorte qu'elle ne se substitue pas à l'homme en tant qu'agent moral. Seul lerecours au hasard, et ceci dès sa conception, peut libérer la machine de laresponsabilité qu'on veut lui faire porter. AlexeiGrinbaum est physicien et philosophe. Chercheur au CEA de Saclay, il estspécialiste des fondements de la mécanique quantique. Conjointement à ces recherches mathématiques, il travaille sur les questions éthiques poséespar les nouvelles technologies.},
	language = {fr},
	publisher = {Desclée De Brouwer},
	author = {Grinbaum, Alexei},
	month = jan,
	year = {2019},
	keywords = {Philosophy / Ethics \& Moral Philosophy}
}


@misc{grinbaum__2019,
	title = {« {Le} jugement éthique est une affaire d'humains, pas de robots »},
	url = {https://usbeketrica.com/article/jugement-ethique-affaire-humains-pas-robots-hasard},
	abstract = {Pour libérer les robots de leur responsabilité, le philosophe et physicien Alexei Grinbaum propose d'intégrer du hasard dans les algorithmes des IA.},
	urldate = {2020-06-08},
	author = {Grinbaum, Alexei},
	month = may,
	year = {2019},
	note = {Library Catalog: usbeketrica.com},
	file = {Snapshot:/home/lauga/Zotero/storage/WLMQFITU/jugement-ethique-affaire-humains-pas-robots-hasard.html:text/html}
}


@misc{grinbaum_conversation_2019,
	title = {La {Conversation} scientifique,  {Des} machines pourront-elles apprendre le bien et le mal ?},
	url = {https://www.franceculture.fr/emissions/la-conversation-scientifique/des-machines-pourront-elles-apprendre-le-bien-et-le-mal},
	abstract = {Régulièrement, les journaux nous informent que l’intelligence artificielle « bat » l’intelligence humaine dans certains secteurs ou dans certaines activités, comme les jeux d’échec ou de go. En d’autres termes, le silicium écrase parfois le neurone. Nous sommes donc, nous autres les humains, des êtres imparfaits, limités, du moins en certains domaines, et nous ne pouvons pas prétendre que nous ne le savons pas. Dès lors, allons-nous abandonner notre idéal d’autonomie et préférer nous confier à la perfection de machines qui pourraient nous relayer ? Qui pourraient choisir et décider à notre place ?},
	language = {Français},
	urldate = {2020-06-08},
	author = {Grinbaum, Alexei},
	month = mar,
	year = {2019}
}

@misc{theeconomist_progress_2009,
	title = {Progress and its perils {\textbar} {Dec} 19th 2009},
	url = {https://www.economist.com/weeklyedition/2009-12-19},
	abstract = {Progress and its perils – Weekly edition of The Economist for Dec 19th 2009. You've seen the news, now discover the story.},
	language = {en},
	urldate = {2020-06-08},
	author = {{TheEconomist}},
	month = dec,
	year = {2009},
	note = {Library Catalog: www.economist.com},
	file = {Snapshot:/home/lauga/Zotero/storage/KKC33PVD/2009-12-19.html:text/html}
}
@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@article{alvarez_on_the_2018,
  author    = {David Alvarez{-}Melis and
               Tommi S. Jaakkola},
  title     = {On the Robustness of Interpretability Methods},
  journal   = {CoRR},
  volume    = {abs/1806.08049},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.08049},
  archivePrefix = {arXiv},
  eprint    = {1806.08049},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-08049.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@incollection{NIPS2017_7062,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}
@article{lacoste2019quantifying,
  title={Quantifying the Carbon Emissions of Machine Learning},
  author={Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  journal={arXiv preprint arXiv:1910.09700},
  year={2019}
}


